

<!DOCTYPE html>
<html lang="en" xmlns:v-bind="http://www.w3.org/1999/xhtml">

<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><title>44 ðŸ¤— Transformers - aPaperADay</title>
<meta charset="utf-8">
<meta name="X-UA-Compatible" content="IE=edge">
<meta name="author" content="Luke Thomas">
<meta name="description" content="The Huggingface Library has contributed to making NLP easier and more open.">
<meta name="keywords" content="">

    <meta charset="utf-8">
    <meta name="X-UA-Compatible" content="IE=edge">
    <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
    <meta content="telephone=no" name="format-detection">
    <meta name="renderer" content="webkit">
    <meta name="theme-color" content="#ffffff">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.1.3/dist/css/bootstrap.min.css" integrity="sha256-eSi1q2PG6J7g7ib17yAaWMcrr5GrtohYChqibrV7PBE=" crossorigin="anonymous">
<link rel="stylesheet" href="/css/journal.css?72940213">

<script src="/js/loadCSS.js"></script>
<script>
    loadCSS("https://fonts.googleapis.com/css?family=Lora|Montserrat|Fira+Mono|Material+Icons");
    (function (d) {
        var config = {
                kitId: 'dwg1tuc',
                scriptTimeout: 3000,
                async: true
            },
            h = d.documentElement, t = setTimeout(function () {
                h.className = h.className.replace(/\bwf-loading\b/g, "") + " wf-inactive";
            }, config.scriptTimeout), tk = d.createElement("script"), f = false,
            s = d.getElementsByTagName("script")[0], a;
        h.className += " wf-loading";
        tk.src = 'https://use.typekit.net/' + config.kitId + '.js';
        tk.async = true;
        tk.onload = tk.onreadystatechange = function () {
            a = this.readyState;
            if (f || a && a != "complete" && a != "loaded") return;
            f = true;
            clearTimeout(t);
            try {
                Typekit.load(config)
            } catch (e) {
            }
        };
        s.parentNode.insertBefore(tk, s)
    })(document);
</script>
<noscript>
    <link rel="stylesheet"
          href="https://fonts.googleapis.com/css?family=Lora|Montserrat|Anonymous+Pro:400|Material+Icons"/>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>
<body>
<!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="top"></div>
<div id="app">
<div class="single-column-drawer-container" ref="drawer"
     v-bind:class="{ 'single-column-drawer-container-active': isDrawerOpen }">
    <div class="drawer-content">
        <div class="drawer-menu">
            <a class="a-block drawer-menu-item false" href="www.apaperaday.com">
                Home
            </a>
            
            <a class="a-block drawer-menu-item false" href="/archives">
                Archive
            </a>
            

            
            
            <a class="a-block drawer-menu-item false" href="/post.html">
                
            </a>
            
            <a class="a-block drawer-menu-item false" href="/About/index.html">
                About
            </a>
            

            
        </div>
    </div>
</div>
<transition name="fade">
    <div v-bind:class="{ 'single-column-drawer-mask': mounted }" v-if="isDrawerOpen" v-on:click="toggleDrawer"></div>
</transition>
<nav ref="navBar" class="navbar sticky-top navbar-light single-column-nav-container">
    <div ref="navBackground" class="nav-background"></div>
    <div class="container container-narrow nav-content">
        <button id="nav_dropdown_btn" class="nav-dropdown-toggle" type="button" v-on:click="toggleDrawer">
            <i class="material-icons">
                menu
            </i>
        </button>
        <a ref="navTitle" class="navbar-brand" href="/">
            aPaperADay
        </a>
    </div>
</nav>
<div class="single-column-header-container" ref="pageHead"
     v-bind:style="{ transform: 'translateZ(0px) translateY('+.3*scrollY+'px)', opacity: 1-navOpacity }">
    <a href="/">
        <div class="single-column-header-title">aPaperADay</div>
        <div class="single-column-header-subtitle"></div>
    </a>
</div>
<div ref="sideContainer" class="side-container">
    <a class="a-block nav-head false" href="/">
        <div class="nav-title">
            aPaperADay.
        </div>
        <div class="nav-subtitle">
            read a deep learning<br>paper a day
        </div>
    </a>

    <div class="nav-link-list">
        
        <a class="a-block no-tint nav-link-item false" href="/archives">
            Archive
        </a>
        

        
        
        <a class="a-block nav-link-item false" href="/post.html">
            
        </a>
        
        <a class="a-block nav-link-item false" href="/About/index.html">
            About
        </a>
        

        
    </div>

    
    <div class="nav-footer">
        Proudly published with Hexo<br>
        
        Theme <a href="https://github.com/SumiMakito/hexo-theme-journal/" target="_blank" rel="noreferrer noopener">Journal.</a> by <a href="https://mak1t0.cc/" target="_blank" rel="noreferrer noopener">Makito</a><br>
        
        &copy; 2021 <a href="www.apaperaday.com">aPaperADay</a>
    </div>
</div>
<div ref="extraContainer" class="extra-container">
    <div class="pagination">
        <a id="globalBackToTop" class="pagination-action animated-visibility" href="#top" :class="{ invisible: scrollY == 0 }">
            <i class="material-icons pagination-action-icon">
                keyboard_arrow_up
            </i>
        </a>

        
    </div>
</div>



<div ref="streamContainer" class="stream-container">
    <div class="post-list-container post-list-container-shadow">
        <div class="post">
            <div class="post-head-wrapper-text-only"
                 style="background-image: url('')">
                <div class="post-title">
                    44 ðŸ¤— Transformers
                    <div class="post-meta">
                        <time datetime="2021-08-06T14:43:57.000Z" itemprop="datePublished">
                            2021-08-06 07:43
                        </time>&nbsp;
                        
    
                        
                        
                        <i class="material-icons" style="">label</i>
                        
                        <a href='/tags/NLP/'>NLP</a>, 
                        
                        <a href='/tags/Huggingface/'>Huggingface</a>
                        
                        
                    </div>
                </div>
            </div>
    
            <div class="post-body-wrapper">
                <div class="post-body">
                    <h3 id="1-read-the-title-and-make-an-opinion-of-whats-in-the-paper-eg-the-area-the-task"><a class="markdownIt-Anchor" href="#1-read-the-title-and-make-an-opinion-of-whats-in-the-paper-eg-the-area-the-task"></a> 1. <strong>Read the title</strong> and make an opinion of what&#x2019;s in the paper (e.g., the area, the task)</h3>
<p>Year: 2020<br>
&#x1F917; Transformers, State-of-the-Art Natural Language Processing</p>
<p>Most people are already pretty familiar with &#x1F917; Transformers, but if not, its a Transformers library, focusing on (for now) NLP.</p>
<h3 id="2-read-the-abstract-well-and-form-a-hypothesis-of"><a class="markdownIt-Anchor" href="#2-read-the-abstract-well-and-form-a-hypothesis-of"></a> 2. <strong>Read the abstract well</strong> and form a hypothesis of</h3>
<ol>
<li>What&#x2019;s new in the paper?</li>
<li>Do you have a clear <em>overview</em> about what the paper is all about?</li>
</ol>
<blockquote>
<p>Transformers is an open-source library with the goal of opening up these advances to the wider machine learning community.</p>
</blockquote>
<p>It sometimes surprises me how much state of the art open source code is out there, but I am certainly thankful because I can benefit from it quite a lot.</p>
<blockquote>
<p>The library consists of carefully engineered state- of-the art Transformer architectures under a unified API.</p>
</blockquote>
<p>I am looking for what is new in this paper, as a contribution to the field, but my personal opinion is that the Huggingface Library is one of the best I&#x2019;ve ever used.</p>
<blockquote>
<p>Transformers is designed to be extensible by researchers, simple for practitioners, and fast and robust in industrial deployments.</p>
</blockquote>
<p>This is a tough balance to maintain.</p>
<h3 id="3-look-at-the-images-and-extract-a-set-of-questions-about-what-is-not-clear-about-their-method-from-the-images-now-your-job-is-to-answer-these-questions-by-reading-the-paper"><a class="markdownIt-Anchor" href="#3-look-at-the-images-and-extract-a-set-of-questions-about-what-is-not-clear-about-their-method-from-the-images-now-your-job-is-to-answer-these-questions-by-reading-the-paper"></a> 3. <strong>Look at the images</strong> and extract a set of &#x201C;questions&#x201D; about what is not clear about their method from the images. Now your job is to answer these questions by reading the paper.</h3>
<p>Figure 1 shows that interest is certainly growing.  More than doubling in less than a year.</p>
<p><img src="fig1.png" alt="fig1"></p>
<p><img src="fig2.png" alt="fig2"></p>
<p>This shows their fundamental architecture that each model is a combination of a Tokenizer, Transformer, and one or many Heads.</p>
<h3 id="4-read-the-method-aiming-to-answer-your-questions-about-the-paper-focus-on-understanding-only-the-things-relevant-for-the-story-ie-to-understand-the-contribution"><a class="markdownIt-Anchor" href="#4-read-the-method-aiming-to-answer-your-questions-about-the-paper-focus-on-understanding-only-the-things-relevant-for-the-story-ie-to-understand-the-contribution"></a> 4. <strong>Read the method</strong> aiming to answer your &#x201C;questions&#x201D; about the paper. Focus on understanding only the things relevant for the story (i.e., to understand the contribution).</h3>
<p>The Library is built to match the standard data pipeline of NLP.  Each corresponding piece of the architecture in Figure 2 matches a piece of the data pipeline.</p>
<ul>
<li><strong>Tokenize</strong> The tokenizer preprocesses the data and prepares it for the model to be fed in token by token.</li>
<li><strong>Transformer</strong> These models are at the heart of the system, and do the heavy processing.</li>
<li><strong>Heads</strong> Each Head is an output to a final prediction, and needs to be designed with the end task in mind.</li>
</ul>
<p><em>So how has the library contributed to making easier and more open?</em></p>
<p><strong>Transformers</strong><br>
The paper notes these are carefully tested, and include a number of different architectures to choose from.</p>
<p><img src="tab1.png" alt="tab1"></p>
<p>To start, these are complex models that took much engineering effort to produce, so to have them freely available is quite something!</p>
<p>There is also the fact that models each approach various design decisions differently, which the API cleanly protects the user from making incompatible decisions.</p>
<p><strong>Tokenizers</strong><br>
A necessary component to NLP is tokenizing and the <em>Transformers</em> library has rewritten their tokenizers in Rust to speed up this classically slow problem.<br>
They also make NLP easier and more open by including some necessary functions inside the tokenizers such as padding and setting max length.</p>
<p><strong>Heads</strong><br>
Each head must be designed with the task in mind, so the library has simplified this by creating a unified API based on the task at hand.  By following a simple naming pattern, <code>ModelNameForSequenceClassification</code>, the developer can easily instantiate a model with the correct head.<br>
Some heads also come with additional functionality such as sampling and beam search.</p>
<p><strong>Community Model Hub</strong><br>
The library also distributes open models which can be contributed by the community.  This enables wide distribution of models and a huge selection for each developer as the ecosystem for trained models grows.</p>
<p>The library creates a unified and simple interface for instantiating its models by passing a model path name through the library.  The library then checks for local version, and will download the model if not.</p>
<p><strong>Deployment</strong><br>
&#x1F917; allows for exporting its models to various intermediate neural network representations, for further compilation.  For example, a <em>Transformers</em> model can be exported to the Open Neural Network Exchange format (ONNX) for potential speedups shown in Figure 4.</p>
<p><img src="fig4.png" alt="fig4"></p>
<h3 id="5-read-the-experiments-to-convince-you-that-the-show-results-are-caused-by-their-claim-be-aware-that-the-experiments-highlighted-are-the-best-scenarios-and-are-fully-hyper-parameter-tuned"><a class="markdownIt-Anchor" href="#5-read-the-experiments-to-convince-you-that-the-show-results-are-caused-by-their-claim-be-aware-that-the-experiments-highlighted-are-the-best-scenarios-and-are-fully-hyper-parameter-tuned"></a> 5. <strong>Read the experiments</strong> to convince you that the show results are caused by their claim. Be aware that the experiments highlighted are the best scenarios and are fully hyper-parameter tuned.</h3>
<p>There are no experiments.</p>
<h3 id="6-make-sure-you-answered-all-your-questions-did-the-authors-convince-you-that-their-story-has-the-effect-that-they-claim"><a class="markdownIt-Anchor" href="#6-make-sure-you-answered-all-your-questions-did-the-authors-convince-you-that-their-story-has-the-effect-that-they-claim"></a> 6. <strong>Make sure you answered all your questions.</strong> Did the authors convince you that their story has the effect that they claim?</h3>
<p>My personal experience holds more weight than the paper, but I can testify that the library is good for two reasons.  Firstly, it is simple to get started and see results.  That is always important for motivation to get things just working.  Second they provide extendability to experiment and analyze.  I was working on an NLP problem and was able to get almost instant results using the &#x1F917; Huggingface library, then in time, I needed to analyze the internal representations of the model and was able to modify a few declarations, and view the inner workings of the model.</p>

                </div>
            </div>
    
            <nav class="post-pagination">
    
    <a class="newer-posts" href="/08/09/2021/45corrGraph/">
        Previous post<br>45 Space-Time Correspondence as a Contrastive Random Walk
    </a>
    
    <span class="page-number"></span>
    
    <a class="older-posts" href="/08/05/2021/43Evolved-Transformer/">
        Next post<br>43 The Evolved Transformer
    </a>
    
</nav>

    
            


        </div>
    </div>
    <div class="single-column-footer">
    Proudly published with Hexo<br>
    
    Theme <a href="https://github.com/SumiMakito/hexo-theme-journal/" target="_blank" rel="noreferrer noopener">Journal.</a> by <a href="https://mak1t0.cc/" target="_blank" rel="noreferrer noopener">Makito</a><br>
    
    &copy; 2021 <a href="www.apaperaday.com">aPaperADay</a>
</div>
</div>

</div>
<script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"
        integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.14.4/dist/umd/popper.min.js"
        integrity="sha256-EGs9T1xMHdvM1geM8jPpoo8EZ1V1VRsmcJz8OByENLA=" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.1.3/dist/js/bootstrap.min.js"
        integrity="sha256-VsEqElsCHSGmnmHXGQzvoWjWwoznFSZc6hs7ARLRacQ=" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/vue@2.5.17/dist/vue.min.js"
        integrity="sha256-FtWfRI+thWlNz2sB3SJbwKx5PgMyKIVgwHCTwa3biXc=" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/smooth-scroll@14.2.1/dist/smooth-scroll.polyfills.min.js"
        integrity="sha256-CI4Gq5E0io1Pv0xM3qPM+NUIOhbIBvC3GiN1Y4KhXpw=" crossorigin="anonymous"></script>
<script src="/js/journal.js?24870265"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->



</body>
</html>
